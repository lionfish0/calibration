{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from calibration import CalibrationSystem, SparseModel\n",
    "import gpflow\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from calibration.errormetrics import MAE, MSE, NMSE, NLPD, compute_test_data\n",
    "from calibration.synthetic import generate_synthetic_dataset, getstaticsensortranform, getmobilesensortranform\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "import pickle\n",
    "from networkx import NodeNotFound\n",
    "from calibration.simple import compute_simple_calibration, compute_simple_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    staticls = np.exp((np.log(24*1000)-np.log(24*5))*x[0][0]+np.log(24*5))\n",
    "    mobilels = np.exp((np.log(24*1000)-np.log(24*5))*x[0][1]+np.log(24*5))\n",
    "    likelihoodstd = np.exp((np.log(150)-np.log(1))*x[0][2]+np.log(1))\n",
    "    kernelscale = np.exp((np.log(150)-np.log(1))*x[0][3]+np.log(1))\n",
    "    \n",
    "    kstatic = gpflow.kernels.RBF(kernelscale,staticls) + gpflow.kernels.Bias(2)\n",
    "    kmobile = gpflow.kernels.RBF(kernelscale,mobilels) + gpflow.kernels.Bias(2)\n",
    "    jitter = 1e-4\n",
    "    while True:\n",
    "        print(\"...\")\n",
    "        try:\n",
    "            ###LR = 0.01 -> 0.04?!\n",
    "            cs = CalibrationSystem(augmentedX, augmentedY, Z, refsensor, 1, transform_fn, transform_fn_loggrad, [kstatic,kmobile], kernelindices,lr=0.01,likelihoodstd=likelihoodstd,minibatchsize=50,jitter=jitter)\n",
    "            \n",
    "        \n",
    "            import time\n",
    "            before = time.time()\n",
    "            print(\"Starting Run\")\n",
    "            elbo_record = cs.run(1000,samples=100) #1000,100\n",
    "            print(time.time()-before)\n",
    "\n",
    "            testX, testY, testtrueY = compute_test_data(X,Y,trueY,refsensor)\n",
    "\n",
    "            testsm = SparseModel(testX,cs.Z,C,cs.k)\n",
    "            qf_mu,qf_cov = testsm.get_qf(cs.mu,cs.scale)\n",
    "            #qf_mu=qf_mu*0\n",
    "            predY = transform_fn(qf_mu[None,:,:],testY[:,0:1],None).numpy()[:,:,0].T\n",
    "            #predY[predY>100]=100\n",
    "            nlpd = NLPD(np.log(testtrueY),np.log(testY[:,0:1])+qf_mu,np.sqrt(np.diag(qf_cov))[:,None])\n",
    "            nmse = NMSE(testtrueY,predY)\n",
    "            mse = MSE(testtrueY,predY)\n",
    "            mae = MAE(testtrueY,predY)\n",
    "            break\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            print(\"EXCEPTION: INCREASING JITTER!\")\n",
    "            jitter = jitter * 10\n",
    "            if jitter>1: \n",
    "                print(\"Jitter > 1, giving up, returning NMSE = 1\")\n",
    "                return 1 #we'll just give up here.\n",
    "            print(\"New Jitter:\",jitter)\n",
    "    print(\"staticls=%5.2f, mobilels=%5.2f likelihoodstd=%5.2f: nlpd=%5.2f nmse=%5.2f mse=%5.2f mae=%5.2f\" % (staticls,mobilels,likelihoodstd,nlpd,nmse,mse,mae))\n",
    "    global searchresults\n",
    "    searchresults.append({'staticls':staticls,'mobilels':mobilels,'likelihoodstd':likelihoodstd,'kernelscale':kernelscale,'nlpd':nlpd,'nmse':nmse,'mse':mse,'mae':mae})\n",
    "    print(searchresults)\n",
    "    return nmse\n",
    "\n",
    "def plotsearchresults(searchresults):\n",
    "    mls = []\n",
    "    lstd = []\n",
    "    nmse = []\n",
    "    sls = []\n",
    "    for sr in searchresults:\n",
    "        mls.append(sr['mobilels'])\n",
    "        lstd.append(sr['likelihoodstd'])\n",
    "        nmse.append(sr['nmse'])\n",
    "        sls.append(sr['staticls'])\n",
    "    nmse=np.array(nmse)\n",
    "    sls = np.array(sls)    \n",
    "    plt.scatter(sls,mls,5+(nmse-np.min(nmse))*15000,facecolor='none',edgecolor='black')\n",
    "    #plt.plot(sls,mls,'-k',alpha=0.1)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('static lengthscale / hours')\n",
    "    plt.ylabel('mobile lengthscale / hours')\n",
    "    #plt.scatter(1726.1398659,2.65914794,1000,marker='x')\n",
    "\n",
    "for randomrestart in range(10):\n",
    "    for noisescale in [20,10,5,2]:\n",
    "        print(\"============================================\")\n",
    "        print(\"Noise Scale: %d\" % noisescale)\n",
    "        Nstatic = 10\n",
    "        Nmobile = 4\n",
    "        Ttotal = 24*180\n",
    "        Nrefs = 4\n",
    "        Nvisitsperdayref = 0.5\n",
    "        Nvisitsperday = 2.5\n",
    "        staticsensornoise = noisescale\n",
    "        mobilesensornoise = noisescale\n",
    "        Nsamps = 1\n",
    "        refsensor,X,Y,trueY,statics,mobilecentres = generate_synthetic_dataset(Nstatic, Nmobile, Ttotal, Nrefs, Nvisitsperdayref, Nvisitsperday, staticsensornoise, mobilesensornoise, Nsamps)\n",
    "\n",
    "        #Plot locations of sensors\n",
    "        plt.figure(figsize=[8,8])\n",
    "        plt.plot(statics[:Nrefs,0],statics[:Nrefs,1],'+g',label='Reference sensors',markersize=10,mew=3)\n",
    "        plt.plot(statics[Nrefs:,0],statics[Nrefs:,1],'x',label='Other static sensors',mew=3)\n",
    "        plt.plot(mobilecentres[:,0],mobilecentres[:,1],'ro',label='mobile sensors')\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.savefig('synthetic_sensorplacement_%d_%d.pdf' % (noisescale,randomrestart))\n",
    "\n",
    "        ##Plot graphs of synthetic data.\n",
    "        plt.figure(figsize=[8,8])\n",
    "        pltidx = 0\n",
    "        for n in range(Nstatic+Nmobile):\n",
    "            keep = X[:,1]==n\n",
    "            if n<Nrefs: continue\n",
    "            pltidx+=1\n",
    "            plt.subplot(5,2,pltidx)\n",
    "            plt.plot(X[keep,0],Y[keep][:,0]/trueY[keep],'.')\n",
    "\n",
    "            keep = X[:,2]==n\n",
    "            plt.plot(X[keep,0],Y[keep][:,1]/trueY[keep],'.')\n",
    "            plt.xlim([0,4500])\n",
    "            plt.ylim([0,2.4])\n",
    "            if pltidx<=8:\n",
    "                #plt.gca().axes.get_xaxis().set_visible(False)\n",
    "                plt.xticks(np.arange(0,5000,1000),['']*5)\n",
    "            else:\n",
    "                plt.xlabel('Hour')\n",
    "            if pltidx%2==0:\n",
    "                #plt.gca().axes.get_yaxis().set_visible(False)\n",
    "                pass\n",
    "            else:\n",
    "                plt.ylabel('Scaling')\n",
    "            r = []\n",
    "            Ts = np.arange(0,Ttotal,1)\n",
    "            for t in Ts:\n",
    "                if n<Nstatic:\n",
    "                    r.append(getstaticsensortranform(t,100,4,n,0))\n",
    "                else:\n",
    "                    r.append(getmobilesensortranform(t,100,n-Nstatic,0))\n",
    "            plt.grid()\n",
    "            plt.plot(Ts,np.array(r)/100,'k-')\n",
    "        plt.savefig('scalingsyntheticdata_%d_%d.pdf' % (noisescale,randomrestart))\n",
    "\n",
    "        ##Compute sensor stats\n",
    "        msperiod = []\n",
    "        ssperiod = []\n",
    "        for sensor in range(0,4):\n",
    "            p = (2*np.pi)/(0.01*(1+0.5*np.cos(4+sensor)))\n",
    "            #print(sensor,p)\n",
    "            msperiod.append(p)\n",
    "        print(\"---\")\n",
    "        for sensor in range(4,10):\n",
    "            p = (2*np.pi)/(0.003*(1+np.cos(sensor)))\n",
    "            print(sensor,p)\n",
    "            ssperiod.append(p)\n",
    "\n",
    "        print(\"Static sensor mean: %0.1f\" % np.exp(np.mean(np.log(ssperiod))))\n",
    "        print(\"Mobile sensor mean: %0.1f\" % np.exp(np.mean(np.log(msperiod))))\n",
    "\n",
    "        print(\"Static sensor median: %0.1f\" % np.median(ssperiod))\n",
    "        print(\"Mobile sensor median: %0.1f\" % np.median(msperiod))\n",
    "\n",
    "\n",
    "        ##Resampling data\n",
    "        #A hacky experiment to encourage reference data to be used more...\n",
    "        #otherwise most minibatches won't include any reference signal?\n",
    "        #is this really dubious...?\n",
    "        print(\"%0.1f%% of colocations are with a reference sensor\" % (100*np.mean(np.any(np.isin(X[:,1:],np.where(refsensor)[0]),1))))\n",
    "        refencounters = np.any(np.isin(X[:,1:],np.where(refsensor)[0]),1)\n",
    "        augmentedX = np.r_[X,np.repeat(X[refencounters,:],10,0)]\n",
    "        augmentedY = np.r_[Y,np.repeat(Y[refencounters,:],10,0)]\n",
    "        print(\"After augmentation...\")\n",
    "        print(\"%0.1f%% of colocations are with a reference sensor\" % (100*np.mean(np.any(np.isin(augmentedX[:,1:],np.where(refsensor)[0]),1))))\n",
    "\n",
    "        #Place inducing points\n",
    "        Z = np.linspace(-200,Ttotal+200,60)[:,None] ##60\n",
    "\n",
    "        C = 1\n",
    "        def transform_fn(samps,Y,sideY):\n",
    "            return Y*tf.exp(samps[:,:,0:1])\n",
    "\n",
    "        def transform_fn_loggrad(samps,Y,sideY):\n",
    "            return samps[:,:,0:1]\n",
    "\n",
    "        kernelindices = [[0]*Nstatic+[1]*Nmobile]\n",
    "\n",
    "        ## Hyperparameter Search using Bayesian Optimisation\n",
    "        #or load...\n",
    "        if False:\n",
    "            searchresults = []\n",
    "            domain = [{'name': 'var_1', 'type': 'continuous', 'domain': (0,1), 'dimensionality':4}]\n",
    "            myBopt = BayesianOptimization(f=f, domain=domain)\n",
    "            myBopt.run_optimization(max_iter=30)\n",
    "            pickle.dump(searchresults,open('searchresults_%d.p' % noisescale,'wb'))\n",
    "            #searchresults = pickle.load(open('searchresults_%d.p' % noisescale,'rb'))\n",
    "\n",
    "            #Plot the bayesian optimisation\n",
    "            plt.figure(figsize=[5,5])\n",
    "            plotsearchresults(searchresults)\n",
    "            plt.savefig('BayesianOptimisationSyntheticData_%d_%d.pdf' % (noisescale,randomrestart))\n",
    "\n",
    "            minnmse = np.inf\n",
    "            bestresult = None\n",
    "            for sr in searchresults:\n",
    "                if sr['nmse']<minnmse:\n",
    "                    minnmse = sr['nmse']\n",
    "                    bestresult = sr\n",
    "            for s in bestresult: print(\"%20s: %0.5f\" % (s,bestresult[s]))\n",
    "\n",
    "        # Then let's solve using a good solution\n",
    "        #this seems to work ok (chosen using noise-scale of 10)\n",
    "        kstatic = gpflow.kernels.RBF(7.645,2201) + gpflow.kernels.Bias(2)#7.645)\n",
    "        kmobile = gpflow.kernels.RBF(7.645,581) + gpflow.kernels.Bias(2)#7.645)\n",
    "        cs = CalibrationSystem(augmentedX, augmentedY, Z, refsensor, 1, transform_fn, transform_fn_loggrad, [kstatic,kmobile], kernelindices,lr=0.01,likelihoodstd=6.02,minibatchsize=100)\n",
    "        import time\n",
    "        before = time.time()\n",
    "        print(\"Starting Run\")\n",
    "        elbo_record = cs.run(3000,samples=200,verbose=True) ##3000 iterations, 200 samples\n",
    "        print(time.time()-before)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(elbo_record)\n",
    "        plt.yscale('log')\n",
    "\n",
    "        ###################################\n",
    "        ###########Simple approach#########\n",
    "        testX, testY, testtrueY = compute_test_data(X,Y,trueY,refsensor)\n",
    "\n",
    "        ## First optimise weightovertime and delta\n",
    "        if True: #False:\n",
    "            bestcomb = None\n",
    "            bestnmse = np.inf\n",
    "            for weightovertime in np.logspace(-2,2,10,base=np.e):\n",
    "                for delta in np.logspace(np.log(24*3),np.log(24*200),10,base=np.e):\n",
    "                    #print(weightovertime,delta)\n",
    "                    #try:\n",
    "\n",
    "                    G,allsp,allcals,allcallists,allpopts,allpcovs,allpoptslists = compute_simple_calibration(X,Y,delta,refsensor,weightovertime=weightovertime,mincolocationsinperiod=1)\n",
    "                    preds,res2,res = compute_simple_predictions(testX,testY,testtrueY,allcals,delta)\n",
    "                    nmse = NMSE(testtrueY[:,0],preds[:,0])\n",
    "                    if nmse<bestnmse:\n",
    "                        bestnmse=nmse\n",
    "                        bestcomb = (weightovertime,delta)\n",
    "                    print(\"%5.2f, %5.2f %5.3f\" % (weightovertime,delta,nmse))\n",
    "        print(\"Best:\")\n",
    "        print(\"bestcomb:\",bestcomb)\n",
    "        print(\"bestnmse:\",bestnmse)\n",
    "        weightovertime=bestcomb[0]#0.135 #0.367\n",
    "        delta = bestcomb[1] #4800#hours\n",
    "        G,allsp,allcals,allcallists,allpopts,allpcovs,allpoptslists = compute_simple_calibration(X,Y,delta,refsensor,weightovertime=weightovertime,mincolocationsinperiod=1)\n",
    "        preds,res2,res = compute_simple_predictions(testX,testY,testtrueY,allcals,delta)\n",
    "\n",
    "\n",
    "        print(\"Using no method!\")\n",
    "        nmse = NMSE(testtrueY[:,0],testY[:,0])\n",
    "        mse = MSE(testtrueY[:,0],testY[:,0])\n",
    "        mae = MAE(testtrueY[:,0],testY[:,0])\n",
    "        print(\"nmse=%5.5f mse=%5.2f mae=%5.2f\" % (nmse,mse,mae))\n",
    "\n",
    "        print(\"Using the graph method:\")\n",
    "        nmse = NMSE(testtrueY[:,0],preds[:,0])\n",
    "        mse = MSE(testtrueY[:,0],preds[:,0])\n",
    "        mae = MAE(testtrueY[:,0],preds[:,0])\n",
    "        print(\"nmse=%5.5f mse=%5.2f mae=%5.2f\" % (nmse,mse,mae))\n",
    "\n",
    "\n",
    "        testsm = SparseModel(testX,cs.Z,1,cs.k)\n",
    "        qf_mu,qf_cov = testsm.get_qf(cs.mu,cs.scale)\n",
    "        #qf_mu=qf_mu*0\n",
    "        predY = transform_fn(qf_mu[None,:,:],testY[:,0:1],None).numpy()[:,:,0].T\n",
    "\n",
    "        nlpd = NLPD(np.log(testtrueY[:,0]),np.log(testY[:,0:1])+qf_mu[:,0],np.sqrt(np.diag(qf_cov)))\n",
    "        keep = ~np.isnan(testtrueY)\n",
    "        nmse = NMSE(testtrueY[:,0],predY[:,0])\n",
    "        mse = MSE(testtrueY[:,0],predY[:,0])\n",
    "        mae = MAE(testtrueY[:,0],predY[:,0])\n",
    "        print(\"Using the variational method\")\n",
    "        print(\"nlpd=%5.2f nmse=%5.5f mse=%5.2f mae=%5.2f\" % (nlpd,nmse,mse,mae))\n",
    "\n",
    "        ## Plot encounters\n",
    "        plt.figure(figsize=[20,4])\n",
    "        plt.vlines(X[:,0],X[:,1],X[:,2])\n",
    "        plt.xlim([500.0,850.0])\n",
    "        plt.hlines(np.array([0,1,2,3]),-1000,5000,'b')\n",
    "        plt.hlines(np.array([13,12,11,10]),-1000,5000,'r')\n",
    "        plt.hlines(np.arange(4,13),-1000,5000,'g',alpha=0.4)\n",
    "        plt.vlines(np.arange(0,3000,24),-4,20,'grey',alpha=0.5)\n",
    "        plt.ylim([-0.5,13.5])\n",
    "        plt.yticks(np.arange(14),np.arange(14));\n",
    "        plt.xticks(np.arange(int(500/24)*24,850,24),np.arange(int(500/24)*24,850,24).astype(int))\n",
    "        plt.ylabel('Sensor')\n",
    "        plt.xlabel('Time / hours')\n",
    "        plt.savefig('syntheticvisits_%d_%d.pdf' % (noisescale,randomrestart))\n",
    "\n",
    "        ##Plot variational approach results\n",
    "        C = 1\n",
    "        pltn=1\n",
    "        plt.figure(figsize=[10,10])\n",
    "        for si,refs in enumerate(refsensor):\n",
    "            if refs: continue\n",
    "            x = np.linspace(0,Ttotal,160)\n",
    "            testX = np.zeros([0,3])\n",
    "            for ci in range(C):\n",
    "                tempX = np.c_[x,np.ones_like(x)*si,np.full_like(x,ci)]\n",
    "                testX = np.r_[testX,tempX]#.astype(int)\n",
    "            testsm = SparseModel(testX,cs.Z,C,cs.k)\n",
    "            qf_mu,qf_cov = testsm.get_qf(cs.mu,cs.scale)\n",
    "            if cs.mulike is not None:\n",
    "                qf_mulike,qf_covlike = testsm.get_qf(cs.mulike,cs.scalelike)\n",
    "                sampslike = testsm.get_samples_one_sensor(cs.mulike,cs.scalelike)\n",
    "            samps = testsm.get_samples_one_sensor(cs.mu,cs.scale)\n",
    "\n",
    "            #plt.figure(figsize=[14,7])\n",
    "            plt.subplot(5,2,pltn)\n",
    "            pltn+=1\n",
    "            plt.plot(x,1/tf.exp(qf_mu[:,0]),'k-',lw=2)\n",
    "            #plt.plot(x,1/np.exp(samps[:,:,0].numpy().T),'k.',alpha=0.005);\n",
    "\n",
    "            plt.plot(x,1/tf.exp((qf_mu[:,0]+2*np.sqrt(np.diag(qf_cov)[:]))),'k-',alpha=0.5)\n",
    "            plt.plot(x,1/tf.exp((qf_mu[:,0]-2*np.sqrt(np.diag(qf_cov)[:]))),'k-',alpha=0.5)\n",
    "\n",
    "            senseX = (X[:,1]==si) & (X[:,2]<Nrefs)\n",
    "            plt.plot(X[senseX,0],Y[senseX,0]/Y[senseX,1],'xr',markersize=12,mew=2)\n",
    "\n",
    "\n",
    "\n",
    "            senseX = (X[:,2]==si) & (X[:,1]<Nrefs)\n",
    "            plt.plot(X[senseX,0],Y[senseX,1]/Y[senseX,0],'xr',markersize=12,mew=2)\n",
    "            senseX = (X[:,1]==si)\n",
    "            plt.plot(X[senseX,0],Y[senseX,0]/Y[senseX,1],'.g',markersize=4)\n",
    "            senseX = (X[:,2]==si)\n",
    "            plt.plot(X[senseX,0],Y[senseX,1]/Y[senseX,0],'.g',markersize=4)    \n",
    "            #plotbars(np.arange(0,np.max(X[:,0]),delta),delta,np.exp(allscales[:,si]),'y')\n",
    "            plt.ylim([0,3])\n",
    "            #plt.yscale('log')\n",
    "            plt.grid()\n",
    "            if si<Nstatic:\n",
    "                for samp in range(10):\n",
    "                    plt.plot([(getstaticsensortranform(t,100.0,Nrefs,si,noisescale=0)/100) for t in np.arange(Ttotal)],'b-',alpha=0.1)\n",
    "            else:\n",
    "                for samp in range(10):\n",
    "                    plt.plot([(getmobilesensortranform(t,100.0,si-Nstatic,noisescale=0)/100) for t in np.arange(Ttotal)],'b-',alpha=0.1)\n",
    "        plt.savefig('results_synth_%d_%d.pdf' % (noisescale,randomrestart))\n",
    "\n",
    "        ##Plot simple graph approach results\n",
    "        plt.figure(figsize=[10,10])\n",
    "        pltn=1\n",
    "        for si,refs in enumerate(refsensor):\n",
    "            if refs: continue\n",
    "            plt.subplot(5,2,pltn)\n",
    "            pltn+=1\n",
    "            for i,t in enumerate(np.arange(0,np.max(X[:,0]),delta)):\n",
    "                try:\n",
    "                    plt.hlines(1/(np.exp(allcals[(si,i)])),t,t+delta)\n",
    "                except KeyError:            \n",
    "                    pass\n",
    "            senseX = (X[:,1]==si) & (X[:,2]<Nrefs)\n",
    "            plt.plot(X[senseX,0],Y[senseX,0]/Y[senseX,1],'xr',markersize=12,mew=1)\n",
    "\n",
    "\n",
    "\n",
    "            senseX = (X[:,2]==si) & (X[:,1]<Nrefs)\n",
    "            plt.plot(X[senseX,0],Y[senseX,1]/Y[senseX,0],'xr',markersize=12,mew=1)\n",
    "            senseX = (X[:,1]==si)\n",
    "            plt.plot(X[senseX,0],Y[senseX,0]/Y[senseX,1],'.g',markersize=3)\n",
    "            senseX = (X[:,2]==si)\n",
    "            plt.plot(X[senseX,0],Y[senseX,1]/Y[senseX,0],'.g',markersize=3)    \n",
    "            #plotbars(np.arange(0,np.max(X[:,0]),delta),delta,np.exp(allscales[:,si]),'y')\n",
    "            plt.ylim([0,2.5])\n",
    "            plt.xlim([0,4300])\n",
    "            #plt.yscale('log')\n",
    "            plt.grid()\n",
    "            if si<Nstatic:\n",
    "                for samp in range(10):\n",
    "                    plt.plot([(getstaticsensortranform(t,100.0,Nrefs,si,noisescale=0)/100) for t in np.arange(Ttotal)],'b-',alpha=0.1)\n",
    "            else:\n",
    "                for samp in range(10):\n",
    "                    plt.plot([(getmobilesensortranform(t,100.0,si-Nstatic,noisescale=0)/100) for t in np.arange(Ttotal)],'b-',alpha=0.1)        \n",
    "            if pltn>=9:\n",
    "                plt.xlabel('Time / hours')\n",
    "            if pltn%2==0:\n",
    "                plt.ylabel('Scaling')\n",
    "            plt.savefig('results_synth_simple_%d_%d.pdf' % (noisescale,randomrestart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment I just saved the cell output (sorry...) ran this regexp on the file:\n",
    "\n",
    "`grep \"Noise\\|nmse\\|Using\" \"DONE Final Paper Synthetic Output.txt\" > \"DONE Final Paper Synthetic Summary.txt\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "patterns = []\n",
    "patterns.append(re.compile(\"nlpd=([ 0-9.]*)\"))\n",
    "patterns.append(re.compile(\"nmse=([ 0-9.]*)\"))\n",
    "patterns.append(re.compile(\" mse=([ 0-9.]*)\"))\n",
    "patterns.append(re.compile(\" mae=([ 0-9.]*)\"))\n",
    "\n",
    "currentmethod = -1\n",
    "currentnoise = -1\n",
    "noisescales = {2:0,5:1,10:2,20:3}\n",
    "invnoisescales = {0:2,1:5,2:10,3:20}\n",
    "#results = np.full([10,4],np.nan)\n",
    "results = [[[[] for _ in range(4)] for _ in range(3)] for _ in range(4)]\n",
    "\n",
    "methodstr = ['no method','the graph','the varia']\n",
    "\n",
    "for line in open('DONE Final Paper Synthetic Summary.txt'):\n",
    "    for i,ms in enumerate(methodstr):\n",
    "        if line[:15]=='Using '+ms:\n",
    "            #print(line)\n",
    "            currentmethod = i\n",
    "    res = re.findall('Noise Scale: ([0-9]*)',line)\n",
    "    if len(res)>0:\n",
    "        currentnoise = noisescales[int(res[0])]\n",
    "    for i,pattern in enumerate(patterns):\n",
    "        #print(pattern,line)\n",
    "        res = re.findall(pattern, line)\n",
    "        if len(res)==0: continue\n",
    "        #print(res[0])\n",
    "        #print(currentmethod,i)\n",
    "        results[currentnoise][currentmethod][i].append(float(res[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "-------1------\n",
      "Noise Scale / $\\mu g\\; m{}^{-3}$ & \\multicolumn{3}{c}{NMSE} & NLPD \\\\\n",
      " & No Method & Multi-hop & Cal. Pair Model & Cal. Pair Model \\\\\n",
      "2 & 0.77 (0.02) & 0.27 (0.01) & 0.18 (0.01) & 42.6 (2.8) \\\\\n",
      "5 & 0.78 (0.02) & 0.44 (0.03) & 0.21 (0.01) & 49.5 (2.3) \\\\\n",
      "10 & 0.97 (0.02) & 0.87 (0.07) & 0.35 (0.01) & 58.2 (2.3) \\\\\n",
      "20 & 1.46 (0.02) & 3.18 (0.69) & 0.84 (0.02) & 87.7 (1.5) \\\\\n",
      " \n",
      "-------2------\n",
      "Noise Scale / $\\mu g\\; m{}^{-3}$ & \\multicolumn{3}{c}{MSE / $(\\mu g\\; m{}^{-3})^2$} & NLPD \\\\\n",
      " & No Method & Multi-hop & Cal. Pair Model & Cal. Pair Model \\\\\n",
      "2 & 410 (16) & 146 (10) & 93 (6) & 42.6 (2.8) \\\\\n",
      "5 & 431 (8) & 244 (18) & 117 (5) & 49.5 (2.3) \\\\\n",
      "10 & 525 (7) & 470 (36) & 188 (4) & 58.2 (2.3) \\\\\n",
      "20 & 788 (9) & 1714 (359) & 453 (6) & 87.7 (1.5) \\\\\n",
      " \n",
      "-------3------\n",
      "Noise Scale / $\\mu g\\; m{}^{-3}$ & \\multicolumn{3}{c}{MAE / $\\mu g\\; m{}^{-3}$} & NLPD \\\\\n",
      " & No Method & Multi-hop & Cal. Pair Model & Cal. Pair Model \\\\\n",
      "2 & 15.6 (0.3) & 8.4 (0.3) & 6.8 (0.2) & 42.6 (2.8) \\\\\n",
      "5 & 16.1 (0.2) & 11.5 (0.4) & 8.1 (0.2) & 49.5 (2.3) \\\\\n",
      "10 & 18.0 (0.1) & 16.0 (0.5) & 10.5 (0.1) & 58.2 (2.3) \\\\\n",
      "20 & 22.3 (0.1) & 27.6 (2.4) & 16.6 (0.1) & 87.7 (1.5) \\\\\n"
     ]
    }
   ],
   "source": [
    "for metric,metricname,units,prec in zip([1,2,3],['NMSE','MSE','MAE'],['',' / $(\\mu g\\; m{}^{-3})^2$',' / $\\mu g\\; m{}^{-3}$'],[2,0,1]):\n",
    "    print(\" \")\n",
    "    print(\"-------%d------\" % metric)\n",
    "    row = [\"Noise Scale / $\\mu g\\; m{}^{-3}$\",\"\\multicolumn{3}{c}{%s%s}\" % (metricname,units),\"NLPD\"]\n",
    "    print(\" & \".join(row)+\" \\\\\\\\\")\n",
    "    row = [\"\",\"No Method\",\"Multi-hop\",\"Cal. Pair Model\",\"Cal. Pair Model\"]\n",
    "    print(\" & \".join(row)+\" \\\\\\\\\")\n",
    "    for noisescale in range(4):\n",
    "        row = []\n",
    "        row.append(\"%d\" % invnoisescales[noisescale])\n",
    "        for method in range(3):\n",
    "            r = results[noisescale][method][metric]\n",
    "            if prec==0: row.append(\"%0.0f (%0.0f)\" % (np.mean(r),np.std(r)/np.sqrt(len(r))))\n",
    "            if prec==1: row.append(\"%0.1f (%0.1f)\" % (np.mean(r),np.std(r)/np.sqrt(len(r))))\n",
    "            if prec==2: row.append(\"%0.2f (%0.2f)\" % (np.mean(r),np.std(r)/np.sqrt(len(r))))\n",
    "        r = results[noisescale][2][0]\n",
    "        row.append(\"%0.1f (%0.1f)\" % (np.mean(r),np.std(r)/np.sqrt(len(r))))\n",
    "\n",
    "        print(\" & \".join(row)+\" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.50131"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
